{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### **pip指令**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\mlinvest\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\user\\anaconda3\\envs\\mlinvest\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\mlinvest\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\mlinvest\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\mlinvest\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\mlinvest\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 停用警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# 禁用所有警告\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下載股票數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "stock_number = '0050.TW'\n",
    "start = datetime.datetime(2000, 1, 1)\n",
    "\n",
    "d = datetime.datetime(2024, 1, 16)\n",
    "\n",
    "df = yf.download(stock_number, start=start, end=end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數據處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Stock_Price_LSTM_Data_Preprocessing(df, mem_his_days, pre_days):\n",
    "    df.dropna(inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    df['label'] = df['Close'].shift(-pre_days)\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    sca_X = scaler.fit_transform(df.iloc[:, :-1])\n",
    "\n",
    "    from collections import deque\n",
    "    deq = deque(maxlen=mem_his_days)\n",
    "\n",
    "    X = []\n",
    "    for i in sca_X:\n",
    "        deq.append(list(i))\n",
    "        if len(deq) == mem_his_days:\n",
    "            X.append(list(deq))\n",
    "\n",
    "    X_lately = X[-pre_days:]\n",
    "    X = X[:-pre_days]\n",
    "\n",
    "    y = df['label'].values[mem_his_days-1:-pre_days]\n",
    "\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y, X_lately\n",
    "\n",
    "X, y, X_lately = Stock_Price_LSTM_Data_Preprocessing(df, 5, 10)\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "print(len(X_lately))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型超參數調整&訓練\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.01, decay_steps=10000, decay_rate=0.9)\n",
    "\n",
    "pre_days = [5, 10, 15, 20, 25, 30]\n",
    "mem_days = [5, 10, 15, 20, 25, 30]\n",
    "lstm_layers = [1, 2, 3, 4, 5]\n",
    "dense_layers = [1, 2, 3, 4, 5]\n",
    "units = [16, 32, 64]\n",
    "\n",
    "for the_pre_days in pre_days:\n",
    "    for the_mem_days in mem_days:\n",
    "        for the_lstm_layers in lstm_layers:\n",
    "            for the_dense_layers in dense_layers:\n",
    "                for the_units in units:\n",
    "                    filepath = f'./models/{{val_mape:.2f}}_{{epoch:02d}}_pre_{the_pre_days}_men_{the_mem_days}_lstm_{the_lstm_layers}_dense_{the_dense_layers}_unit_{the_units}.h5'\n",
    "\n",
    "                    checkpoint = ModelCheckpoint(\n",
    "                        filepath=filepath,\n",
    "                        #save_weights_only初訓練設定true只保存值無法讀檔\n",
    "                        save_weights_only=True,\n",
    "                        monitor='val_mape',\n",
    "                        mode='min',\n",
    "                        save_best_only=True)\n",
    "\n",
    "                    X, y, X_lately = Stock_Price_LSTM_Data_Preprocessing(df, the_mem_days, the_pre_days)\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.1)\n",
    "\n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(the_units, input_shape=X.shape[1:], return_sequences=True))\n",
    "                    model.add(BatchNormalization())\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(Dropout(0.1))\n",
    "\n",
    "                    for i in range(the_lstm_layers):\n",
    "                        model.add(LSTM(the_units, return_sequences=True))\n",
    "                        model.add(BatchNormalization())\n",
    "                        model.add(Activation('relu'))\n",
    "                        model.add(Dropout(0.1))\n",
    "\n",
    "                    model.add(LSTM(the_units))\n",
    "                    model.add(BatchNormalization())\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(Dropout(0.1))\n",
    "\n",
    "                    for i in range(the_dense_layers):\n",
    "                        model.add(Dense(the_units))\n",
    "                        model.add(BatchNormalization())\n",
    "                        model.add(Activation('relu'))\n",
    "                        model.add(Dropout(0.1))\n",
    "\n",
    "                    model.add(Dense(1))\n",
    "\n",
    "                    # 使用自定義的學習率\n",
    "                    model.compile(optimizer=Adam(learning_rate=lr_schedule), loss='mse', metrics=['mape'])\n",
    "\n",
    "                    model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 儲存模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.01, decay_steps=10000, decay_rate=0.9)\n",
    "\n",
    "pre_days = [5]  \n",
    "mem_days = [25]\n",
    "lstm_layers = [2]\n",
    "dense_layers = [5]\n",
    "units = [64]\n",
    "\n",
    "for the_pre_days in pre_days:\n",
    "    for the_mem_days in mem_days:\n",
    "        for the_lstm_layers in lstm_layers:\n",
    "            for the_dense_layers in dense_layers:\n",
    "                for the_units in units:\n",
    "                    filepath = f'./models/{{val_mape:.2f}}_{{epoch:02d}}_pre_{the_pre_days}_men_{the_mem_days}_lstm_{the_lstm_layers}_dense_{the_dense_layers}_unit_{the_units}.h5'\n",
    "\n",
    "\n",
    "                    checkpoint = ModelCheckpoint(\n",
    "                        filepath=filepath,\n",
    "                        #save_weights_only二次訓練設定false才能讀擋\n",
    "                        save_weights_only=False,\n",
    "                        monitor='val_mape',\n",
    "                        mode='min',\n",
    "                        save_best_only=True)\n",
    "\n",
    "                    X, y, X_lately = Stock_Price_LSTM_Data_Preprocessing(df, the_mem_days, the_pre_days)   \n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.1)\n",
    "\n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(the_units, input_shape=X.shape[1:], return_sequences=True))\n",
    "                    model.add(BatchNormalization())\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(Dropout(0.1))\n",
    "\n",
    "                    for i in range(the_lstm_layers):\n",
    "                        model.add(LSTM(the_units, return_sequences=True))\n",
    "                        model.add(BatchNormalization())\n",
    "                        model.add(Activation('relu'))\n",
    "                        model.add(Dropout(0.1))\n",
    "\n",
    "                    model.add(LSTM(the_units))\n",
    "                    model.add(BatchNormalization())\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(Dropout(0.1))\n",
    "\n",
    "                    for i in range(the_dense_layers):\n",
    "                        model.add(Dense(the_units))\n",
    "                        model.add(BatchNormalization())\n",
    "                        model.add(Activation('relu'))\n",
    "                        model.add(Dropout(0.1))\n",
    "\n",
    "                    model.add(Dense(1))\n",
    "\n",
    "                    # 使用自定義的學習率\n",
    "                    model.compile(optimizer=Adam(learning_rate=lr_schedule), loss='mse', metrics=['mape'])\n",
    "\n",
    "                    model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尋找模型檔案\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 確定當前工作目錄\n",
    "current_directory = %pwd  # %pwd 這個是 Jupyter Notebook 內建的魔術指令，如果在其他 IDE 中需要替換成 os.getcwd()\n",
    "\n",
    "# 指定檔案路徑\n",
    "folder_path = os.path.join(current_directory, 'models')\n",
    "\n",
    "# 列出該資料夾下的所有檔案\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# 過濾出以 '.h5' 結尾的檔案\n",
    "model_files = [file for file in files if file.endswith('.h5')]\n",
    "\n",
    "# 輸出所有模型檔案\n",
    "print(\"找到的模型檔案：\")\n",
    "for model_file in model_files:\n",
    "    print(os.path.join(folder_path, model_file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入&評估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 提供最佳模型的檔案路徑\n",
    "filepath = r'{best_data_filepath}'\n",
    "\n",
    "# 定義任何自定義的層或函數\n",
    "custom_objects = {\n",
    "    # 如果有自定義的層或函數，請在這裡添加\n",
    "}\n",
    "\n",
    "# 載入模型\n",
    "best_model = load_model(filepath, custom_objects=custom_objects)\n",
    "\n",
    "# 顯示模型摘要\n",
    "best_model.summary()\n",
    "\n",
    "# 評估模型表現\n",
    "best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# 預測結果\n",
    "pre = best_model.predict(X_test)\n",
    "print(len(pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出視覺化結果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 繪製測試集與預測結果的對比圖\n",
    "df_time = df.index[-len(y_test):]  # df_time 是與 y_test 相對應的時間軸\n",
    "plt.plot(df_time, y_test, color='blue', label='price')\n",
    "plt.plot(df_time, pre, color='purple', label='predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLInvest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
