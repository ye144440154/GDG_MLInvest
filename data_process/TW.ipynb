{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install yfinance pandas requests beautifulSoup4\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financial_statement(sheet_type,co_id, industry, year, season, base_dir):\n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "    sheet_type 會計表類型 = I(income statement) B(Balance sheet) S(Statement of cash flows)\n",
    "    co_id=\"\" #四位數公司代碼\n",
    "    year=\"\" #國歷年分\n",
    "    season=\"\" #1~4 \n",
    "    \"\"\"\n",
    "    sheet_code=\"\"\n",
    "    if (sheet_type == \"I\"):\n",
    "        sheet_code = \"4\"\n",
    "    elif (sheet_type == \"B\"):\n",
    "        sheet_code = \"3\"\n",
    "    elif (sheet_type == \"S\"):\n",
    "        sheet_code = \"5\"\n",
    "    else:\n",
    "        print(\"Invalid sheet_type!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    url = \"https://mopsov.twse.com.tw/mops/web/t164sb0{sheet_code}?encodeURIComponent=1&step=1&firstin=1&off=1&keyword4=&code1=&TYPEK2=&checkbtn=&queryName=co_id&inpuType=co_id&TYPEK=all&isnew=false&co_id={co_id}&year={year}&season=0{season}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    # 取得網頁內容\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.encoding = 'utf8'  # 根據網頁編碼設定，若非 Big5 可調整\n",
    "    html_content = response.text\n",
    "\n",
    "\n",
    "    # 使用 BeautifulSoup 解析 HTML\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    except ValueError :\n",
    "        print(f\"response has nothing to do. co_id:{co_id}\")\n",
    "\n",
    "    # 找到 <div id=\"table01\">\n",
    "    div_table = soup.find('div', id='table01')\n",
    "    if div_table:\n",
    "        # 將 <div id=\"table01\"> 中的 HTML 轉換為字串，再用 pandas 讀取表格\n",
    "        table_html = str(div_table)\n",
    "        tables = pd.read_html(table_html)\n",
    "        save_path = os.path.join(base_dir,industry,year,season)\n",
    "        if not os.path.exists(base_dir):\n",
    "            os.makedirs(base_dir)\n",
    "        tables[1].to_csv(os.path.join(save_path,\"TW_{co_id}_{year}_{season}_{sheet_type}.csv\"), index=False, encoding=\"utf-8-sig\") # 第一個table1是目錄 需要的是第二個\n",
    "        print(tables)\n",
    "    else : \n",
    "        print(\"爬蟲失敗 沒有找到表格\")\n",
    "\n",
    "    print(f\"TW_{co_id}_{year}_{season}_{sheet_type}.csv爬蟲完成,休眠5秒\")\n",
    "    time.sleep(5) # 處理防爬 不確定秒數夠不夠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1101    水泥工業\n",
      "TW_1101_104_1_I.csv爬蟲完成,休眠5秒\n",
      "TW_1101_104_1_B.csv爬蟲完成,休眠5秒\n",
      "TW_1101_104_1_S.csv爬蟲完成,休眠5秒\n",
      "TW_1101_104_2_I.csv爬蟲完成,休眠5秒\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (end_year\u001b[38;5;241m-\u001b[39myear_range,end_year):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m season \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m---> 25\u001b[0m         \u001b[43mget_financial_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindustry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseason\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 取得損益表\u001b[39;00m\n\u001b[0;32m     26\u001b[0m         get_financial_statement(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, code, industry, year, season, base_dir) \u001b[38;5;66;03m# 取得資產負債表\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         get_financial_statement(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, code, industry, year, season, base_dir) \u001b[38;5;66;03m# 取得現金流量表\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 50\u001b[0m, in \u001b[0;36mget_financial_statement\u001b[1;34m(sheet_type, co_id, industry, year, season, base_dir)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tables)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTW_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mco_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv爬蟲完成,休眠5秒\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 讀取 JSON 檔案\n",
    "json_path = \"TW_stock.json\"\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    tw_stock = json.load(f)\n",
    "\n",
    "# 檔案儲存根目錄\n",
    "base_dir = \"./TW\"\n",
    "\n",
    "# 確保目錄存在\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "\n",
    "end_year = 114\n",
    "year_range = 10\n",
    "\n",
    "for company_code, info in tw_stock.items():\n",
    "    code = info.get(\"代號\")\n",
    "    industry = info.get(\"產業別\")\n",
    "\n",
    "    if(len(code) == 4 and industry != \"\"): #過濾非公司股票 \n",
    "        print(code,\"  \",industry)\n",
    "        for year in range (end_year-year_range,end_year):\n",
    "            for season in range(1,5):\n",
    "                get_financial_statement(\"I\", code, industry, year, season, base_dir) # 取得損益表\n",
    "                get_financial_statement(\"B\", code, industry, year, season, base_dir) # 取得資產負債表\n",
    "                get_financial_statement(\"S\", code, industry, year, season, base_dir) # 取得現金流量表\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "co_id=\"\" #四位數公司代碼\n",
    "year=\"\" #國歷年分\n",
    "season=\"\" #1~4\n",
    "url = \"https://mopsov.twse.com.tw/mops/web/t164sb03?encodeURIComponent=1&step=1&firstin=1&off=1&keyword4=&code1=&TYPEK2=&checkbtn=&queryName=co_id&inpuType=co_id&TYPEK=all&isnew=false&co_id={co_id}&year={year}&season=0{season}\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "# 取得網頁內容\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "response.encoding = 'utf8'  # 根據網頁編碼設定，若非 Big5 可調整\n",
    "html_content = response.text\n",
    "\n",
    "# 使用 BeautifulSoup 解析 HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# 找到 <div id=\"table01\">\n",
    "div_table = soup.find('div', id='table01')\n",
    "if div_table:\n",
    "    # 將 <div id=\"table01\"> 中的 HTML 轉換為字串，再用 pandas 讀取表格\n",
    "    table_html = str(div_table)\n",
    "    tables = pd.read_html(table_html)\n",
    "    tables[1].to_csv(\"table01.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(tables)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def financial_statement(year, season, report_type='綜合損益彙總表'):\n",
    "    \"\"\"\n",
    "    抓取公開資訊觀測站中指定年度、季別的財報資料\n",
    "    report_type 可設定為：\n",
    "      '綜合損益彙總表'  → 損益表\n",
    "      '資產負債彙總表'  → 資產負債表\n",
    "      '營益分析彙總表'  → 營利分析表\n",
    "    注意：若輸入西元年，程式內部會先轉為民國年。\n",
    "    \"\"\"\n",
    "    # 若傳入西元年，轉為民國年\n",
    "    if year > 1000:\n",
    "        year -= 1911\n",
    "\n",
    "    # 根據報表類型選擇對應的 URL\n",
    "    if report_type == '綜合損益彙總表':\n",
    "        url = 'https://mops.twse.com.tw/mops/web/ajax_t163sb04'\n",
    "    elif report_type == '資產負債彙總表':\n",
    "        url = 'https://mops.twse.com.tw/mops/web/ajax_t163sb05'\n",
    "    elif report_type == '營益分析彙總表':\n",
    "        url = 'https://mops.twse.com.tw/mops/web/ajax_t163sb06'\n",
    "    else:\n",
    "        raise ValueError(\"不支援的報表類型！請選 '綜合損益彙總表'、'資產負債彙總表' 或 '營益分析彙總表'。\")\n",
    "    \n",
    "    # 設定 POST 請求的參數\n",
    "    payload = {\n",
    "        'encodeURIComponent': 1,\n",
    "        'step': 1,\n",
    "        'firstin': 1,\n",
    "        'off': 1,\n",
    "        'keyword4':\"\", \n",
    "        'code1': \"\",\n",
    "        'TYPEK2':\"\" ,\n",
    "        'checkbtn':\"\", \n",
    "        'queryName': 'co_id',\n",
    "        'inpuType': 'co_id',\n",
    "        'TYPEK': all,\n",
    "        'isnew': False,\n",
    "        'co_id': \"1101\",\n",
    "        'year': \"110\",\n",
    "        'season': \"02\"\n",
    "    }\n",
    "    \n",
    "    #url = \"https://mopsov.twse.com.tw/mops/web/t164sb03?encodeURIComponent=1&step=1&firstin=1&off=1&keyword4=&code1=&TYPEK2=&checkbtn=&queryName=co_id&inpuType=co_id&TYPEK=all&isnew=false&co_id=1101&year=110&season=02\"\n",
    "    url = \"https://mopsov.twse.com.tw/server-java/t164sb01?step=1&CO_ID=1101&SYEAR=2021&SSEASON=2&REPORT_ID=C#BalanceSheet\"\n",
    "    # 發出 POST 請求\n",
    "    r = requests.post(url)\n",
    "    # 預設編碼可能正確，也可以試試 utf8 或 big5，這裡通常使用 utf8\n",
    "    r.encoding = 'big5'\n",
    "    \n",
    "    # 利用 pandas 讀取 HTML 中的表格\n",
    "    try:\n",
    "        dfs = pd.read_html(r.text, header=None)\n",
    "    except ValueError:\n",
    "        raise RuntimeError(\"無法從回傳資料中解析出表格，請檢查是否因查詢條件（例如當季財報尚未揭露）而無資料。\")\n",
    "    \n",
    "    '''\n",
    "    # 假設第一個表格通常為標題說明，取後續的所有表格並合併\n",
    "    df = pd.concat(dfs[1:], axis=0, sort=False)\n",
    "    # 若表格內有多層欄位，可嘗試用以下方式調整：\n",
    "    if hasattr(df.columns, 'levels'):\n",
    "        df.columns = df.columns.get_level_values(1)\n",
    "    \n",
    "    # 以下範例示意轉換數值，實際情況可能需要依據報表格式做進一步處理\n",
    "    df = df.apply(lambda col: pd.to_numeric(col, errors='coerce'))\n",
    "    '''\n",
    "    for i, table in enumerate(dfs):\n",
    "\n",
    "        print(f\"表格 {i}：\")\n",
    "        print(table.head())\n",
    "        print(\"-\" * 50)\n",
    "        if ( \"資產負債表Balance Sheet\" in table.to_string()):\n",
    "            table.head().to_csv(f\"TW/test/{i}.csv\",index = False)\n",
    "    # TODO: 分成每個公司的三表 #########################\n",
    "\n",
    "    \"\"\"\n",
    "    將單一公司爬下來的三表資料依照以下規則儲存：\n",
    "      1. base_dir (例如 \"TW\")\n",
    "      2. 產業分類 (例如 \"電子業\")\n",
    "      3. 公司資料夾 (以 TW 股票代碼命名，如 \"2330\")\n",
    "      4. 各個報表資料（儲存為 CSV 檔）\n",
    "      \n",
    "    同時刪除每個 DataFrame 中所有完全為空值的欄位與列。\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # 讀取 JSON 檔案\n",
    "    json_path = \"/mnt/data/TW_stock.json\"\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        stock_data = json.load(f)\n",
    "\n",
    "    # 檔案儲存根目錄\n",
    "    base_dir = \"TW\"\n",
    "\n",
    "    # 確保目錄存在\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "\n",
    "    # 遍歷 CSV 每一行\n",
    "    for _, row in df.iterrows():\n",
    "        stock_code = str(row[\"代號\"])  # 假設 CSV 中有 \"代號\" 欄位\n",
    "\n",
    "        # 獲取產業分類\n",
    "        industry = stock_data.get(stock_code, {}).get(\"產業別\", \"未知分類\")\n",
    "\n",
    "        # 建立目錄 `TW/產業分類/代碼/`\n",
    "        save_path = os.path.join(base_dir, industry, stock_code, year)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        # 儲存該行 CSV\n",
    "        row_df = pd.DataFrame([row])\n",
    "        row_df=row_df.dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "        row_df.to_csv(os.path.join(save_path, f\"{stock_code}.csv\"), index=False, encoding='utf8')\n",
    "        print(f\"已儲存：{save_path}\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# 使用範例：抓取 2020 年第一季（民國 109 年第一季）的綜合損益彙總表（損益表）\n",
    "if __name__ == \"__main__\":\n",
    "    print(financial_statement(109, 1, report_type='綜合損益彙總表'))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_company_reports(base_dir, company_data):\n",
    "    \"\"\"\n",
    "    將單一公司爬下來的三表資料依照以下規則儲存：\n",
    "      1. base_dir (例如 \"TW\")\n",
    "      2. 產業分類 (例如 \"電子業\")\n",
    "      3. 公司資料夾 (以 TW 股票代碼命名，如 \"2330\")\n",
    "      4. 各個報表資料（儲存為 CSV 檔）\n",
    "      \n",
    "    同時刪除每個 DataFrame 中所有完全為空值的欄位與列。\n",
    "    \n",
    "    \"\"\"\n",
    "    stock_code = company_data.get(\"公司代號\")\n",
    "    industry = company_data.get(\"產業分類\")\n",
    "    \n",
    "    # 報表的鍵，可以根據你的資料調整\n",
    "    report_keys = [\"綜合損益彙總表\", \"資產負債彙總表\", \"營益分析彙總表\"]\n",
    "    \n",
    "    # 建立資料夾層級：base_dir/產業分類/股票代碼\n",
    "    company_dir = os.path.join(base_dir, str(industry), str(stock_code))\n",
    "    os.makedirs(company_dir, exist_ok=True)\n",
    "    \n",
    "    for key in report_keys:\n",
    "        df = company_data.get(key)\n",
    "        if df is None:\n",
    "            print(f\"{key} 資料不存在，跳過。\")\n",
    "            continue\n",
    "        # 刪除所有全為 NaN 的欄位與列\n",
    "        df_clean = df.dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "        # 儲存為 CSV（可根據需要調整編碼）\n",
    "        file_path = os.path.join(company_dir, f\"{key}.csv\")\n",
    "        df_clean.to_csv(file_path, index=False, encoding='utf8')\n",
    "        print(f\"已儲存：{file_path}\")\n",
    "\n",
    "# 範例：假設你已爬到一家公司的資料\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    company_data = financial_statement(109, 1, report_type='綜合損益彙總表')\n",
    "    base_directory = \"./TW\"  # 最外層資料夾\n",
    "    save_company_reports(base_directory, company_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLInvest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
